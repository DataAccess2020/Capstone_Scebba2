---
title: "Discussion on Twitter between left and right politicians in Lombardia"
author: "Sara Alice Scebba"
date: "2022-12-23"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
Link to Capstone_Scebba: https://github.com/DataAccess2020/Capstone_Scebba.git
Link to Capstone_Scebba2: https://github.com/DataAccess2020/Capstone_Scebba2.git

Total commit for Capstone_Scebba: 16 commits
Total commit for Capstone_Scebba2: 11 commits



## Introduction

In this project, I decided to study the discussion of Lombardia's politicians on Twitter. On February, people who live in this region of Italy will vote for the president and the Consiglio Regionale. Thus, my interest is to analyse around what is the discussion between politicians from the right and left wing.



## Method of Data collecting 



1. Creating a Twitter Developer account and Authenitcated in R

In order to download data from Twitter and analyse them in R, I created a Twitter Developer account and I generated the passwords.

In R I authenticated using the package "rtweet" and the following code:

```{r, eval=FALSE}
token <- create_token(
  app = "capstone_project_scebba",
  consumer_key = API_k,
  consumer_secret = API_seck,
  access_token = access_t,
  access_secret = access_sect
)
```



2. List of politicians

On my Twitter account, I created a two list with members of the Consiglio Regionale and the most famous mayors for both parts.

Then, I uploaded in R using the code:

```{r, eval=FALSE}
right_lomb = lists_members(
  list_id = "1604889112456138769",
  slug = NULL, 
  owner_user = NULL,
  n = 26,
  cursor = "-1",
  token = NULL,
  retryonratelimit = TRUE,
  verbose = TRUE,
  parse = TRUE,
)

left_lomb = lists_members(
  list_id = "1605175421473112064",
  slug = NULL, 
  owner_user = NULL,
  n = 23,
  cursor = "-1",
  token = NULL,
  retryonratelimit = TRUE,
  verbose = TRUE,
  parse = TRUE,
)
```



3. Downloading the tweets 

I downloaded the time line of the two lists I have created previuosly with:

```{r, eval=FALSE}
tweets_left <- rtweet::get_timeline(user = left_lomb$screen_name,
                                    n = 150000,
                                    verbose = T,
                                    parse = T,
                                    Sys.sleep(0.5)
)


tweets_right <- rtweet::get_timeline(user = right_lomb$screen_name,
                                     n = 150000,
                                     verbose = T,
                                     parse = T,
                                     Sys.sleep(0.5)
)
```

Then, I save the data in cvs

```{r, eval=FALSE}
tweets_left_lomb <- sapply(tweets_left, as.character) 
write.csv(tweets_left_lomb, "tweets_left_lomb.cvs",
          row.names = F)


tweets_right_lomb <- sapply(tweets_right, as.character) 
write.csv(tweets_right_lomb, "tweets_right_lomb.cvs",
          row.names = F)
```

Here is where I got troublesome because I commited the two cvs files and tried to push them to GitHub, but the two files were too heavy and from this point on all the other commits I tried to push didn't go. 



## Data Analysis with words cloud



1. Creating a list of words

I did a bit of data cleaning of the tweets:

```{r, eval=FALSE}
stop_words_ita<-tibble(word=stopwords("it"))

tweets_left$full_text <- gsub("https\\S*", "", tweets_left$full_text) 
tweets_left$full_text <- gsub("@\\S*", "", tweets_left$full_text) 
tweets_left$full_text <- gsub("amp", "", tweets_left$full_text) 
tweets_left$full_text <- gsub("[\r\n]", "", tweets_left$full_text)
tweets_left$full_text <- gsub("[[:punct:]]", "", tweets_left$full_text)


tweets_right$full_text <- gsub("https\\S*", "", tweets_right$full_text) 
tweets_right$full_text <- gsub("@\\S*", "", tweets_right$full_text) 
tweets_right$full_text <- gsub("amp", "", tweets_right$full_text) 
tweets_right$full_text <- gsub("[\r\n]", "", tweets_right$full_text)
tweets_right$full_text <- gsub("[[:punct:]]", "", tweets_right$full_text)
```

Then, I looked at the most used words by each part:

```{r, eval=FALSE}
words_left <- tibble(text = tweets_left$full_text) %>%
  unnest_tokens(word, text) %>%
  dplyr::anti_join(stop_words_ita)%>%
  count(word, sort = TRUE)

words_right <- tibble(text = tweets_right$full_text) %>%
  unnest_tokens(word, text) %>%
  dplyr::anti_join(stop_words_ita)%>%
  count(word, sort = TRUE)
```



2. Words cloud

Finally I created two words cloud to highlight the most used words used by left and right politicians in Lombardia

```{r, eval=FALSE}
cloud_left <- wordcloud2(data=words_left, size=0.35, shuffle =F,
                         color='random-dark')

print(cloud_left)


cloud_right <- wordcloud2(data=words_right, size=0.35, shuffle =F,
                          color='random-dark')

print(cloud_right)
```

![Words Cloud of Left Politicians in Lombardia](C:/Users/utente/OneDrive/Desktop/sara/magistrale/data access/Capstone_Scebba2/report/words_cloud_left.png)

![Words Cloud of Right Politicians in Lombardia](C:/Users/utente/OneDrive/Desktop/sara/magistrale/data access/Capstone_Scebba2/report/word_cloud_right.png)




